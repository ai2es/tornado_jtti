{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8d6610-798e-4152-89b1-ec49446fae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from metpy.calc import dewpoint_from_relative_humidity\n",
    "from metpy.units import units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f941d33-2de9-44e8-be0c-e3a0117e50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/glade/p/cisl/aiml/jtti_tornado/gridrad_storm_tracks/\"\n",
    "path_save = \"/glade/p/cisl/aiml/jtti_tornado/gridrad_soundings/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b713967-9a8b-4662-89f9-64fde78766a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['grid_point_latitudes_deg', 'grid_point_longitudes_deg', 'grid_point_rows', 'grid_point_columns', 'polygon_object_latlng_deg', 'polygon_object_rowcol']\n",
    "for year in [d for d in os.listdir(path_data) if d.startswith('20')]:\n",
    "    dates = os.listdir(os.path.join(path_data, year))\n",
    "    print(year, len(dates))\n",
    "    for date in dates:\n",
    "        files = os.listdir(os.path.join(path_data, year, date, 'scale_314159265m2'))\n",
    "        df = pd.DataFrame()\n",
    "        for file in files:\n",
    "            df = df.append(pd.read_pickle(os.path.join(path_data, year, date, \"scale_314159265m2\", file)),\n",
    "                           ignore_index=True)\n",
    "        df = df.drop(columns=columns_to_drop)\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.to_parquet(os.path.join(path_save, \"raw\", f\"{date}.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a0b099-d01b-4475-90af-cd6943917824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_storm_ids(df, ds, date):\n",
    "#     print(date)\n",
    "    df_storm_ids = list(df['full_id_string'])\n",
    "    df_storm_ids.sort()\n",
    "#     print(f\"\\t- DF count of full_id_strings: {len(df_storm_ids)}\")\n",
    "#     print(f\"\\t- DF count of unique full_id_strings: {len(set(df_storm_ids))}\")\n",
    "    \n",
    "    ds_storm_ids = list(ds['full_storm_id_strings'].values)\n",
    "    ds_storm_ids = [i.decode('UTF-8') for i in ds_storm_ids]\n",
    "    ds_storm_ids.sort()\n",
    "#     print(f\"\\t- DS count of full_id_strings: {len(ds_storm_ids)}\")\n",
    "#     print(f\"\\t- DS count of unique full_id_strings: {len(set(ds_storm_ids))}\")\n",
    "    \n",
    "    return df_storm_ids, ds_storm_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0531aa-b96b-4848-a12d-75f84814a3cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(os.path.join(\"/glade/p/cisl/aiml/jtti_tornado/gridrad_radar_zarr/\", \"storm_radar_20110108.zarr\"))\n",
    "\n",
    "heights = list(ds['sounding_heights_m_agl'].values)\n",
    "names = [i.decode('UTF-8') for i in ds['sounding_field_names'].values]\n",
    "\n",
    "columns_flattened = []\n",
    "for n in names:\n",
    "    for h in heights:\n",
    "        columns_flattened.append(n+'_'+str(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0e0864-d410-4540-a404-80b01fd0215d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'temperature_kelvins', b'pressure_pascals', b'u_wind_m_s01',\n",
       "       b'v_wind_m_s01', b'relative_humidity_unitless',\n",
       "       b'specific_humidity', b'virtual_potential_temperature_kelvins'],\n",
       "      dtype='|S37')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"sounding_field_names\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da8c1bd-2543-4126-8925-30f8afaf67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dewpoint(df):\n",
    "    for h in heights:\n",
    "        df_RH = units.Quantity(np.array(df[f'relative_humidity_unitless_{h}']), \"dimensionless\")\n",
    "        df_TMP =  units.Quantity(np.array(df[f'temperature_kelvins_{h}']), \"K\")\n",
    "        df[f't_dewpoint_{h}'] = dewpoint_from_relative_humidity(df_TMP, df_RH) \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6bbb8e-5de0-45ed-91f2-b3cf6fd699bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_all = os.listdir(os.path.join(path_save, \"raw\"))\n",
    "dates_saved = []\n",
    "dates_unavailable = []\n",
    "for f in dates_all:\n",
    "    date = f[:8]\n",
    "    try:\n",
    "        ds = xr.open_zarr(os.path.join(\"/glade/p/cisl/aiml/jtti_tornado/gridrad_radar_zarr/\", f\"storm_radar_{date}.zarr\"))\n",
    "        dates_saved.append(date)\n",
    "    except Exception as e:\n",
    "#         print(date, e)\n",
    "        dates_unavailable.append(date)\n",
    "        continue\n",
    "dates_saved = dates_saved.sort()\n",
    "dates_unavailable = dates_unavailable.sort()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02348fe2-8d4f-4681-bd84-6e4801fb9cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_saved_files = os.listdir(os.path.join(path_save, \"final\"))\n",
    "dates_saved_files = dates_saved_files.sort()\n",
    "dates_saved == dates_saved_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ad179-ca2f-4f5e-a58d-300d7da53dde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in os.listdir(os.path.join(path_save, \"raw\")):\n",
    "    date = f[:8]\n",
    "    df_new = pd.DataFrame(columns = list(df.columns) + columns_flattened)\n",
    "    df = pd.read_parquet(os.path.join(path_save, \"raw\", f))\n",
    "    try:\n",
    "        ds = xr.open_zarr(os.path.join(\"/glade/p/cisl/aiml/jtti_tornado/gridrad_radar_zarr/\", f\"storm_radar_{date}.zarr\"))\n",
    "    except Exception as e:\n",
    "        print(date, e)\n",
    "        continue\n",
    "    df_storm_ids, ds_storm_ids = summarize_storm_ids(df, ds, date)\n",
    "    for id_string in list(set(df_storm_ids)):\n",
    "        df_len = np.where(np.array(df_storm_ids) == id_string)[0].shape[0]\n",
    "        ds_len = np.where(np.array(ds_storm_ids) == id_string)[0].shape[0]\n",
    "        if df_len == ds_len:\n",
    "            df_temp = df[df['full_id_string'] == id_string]\n",
    "            ds_idx = np.where(np.array(ds_storm_ids) == id_string)[0]\n",
    "            soundings = ds['sounding_matrix'].values[ds_idx].reshape(df_len, -1)\n",
    "            df_temp[columns_flattened] = soundings\n",
    "            df_new = df_new.append(df_temp)\n",
    "        else:\n",
    "            print(f\"For date {date} & id_string {id_string}, DF contains {np.where(np.array(df_storm_ids) == id_string)[0].shape[0]}, DS contains {np.where(np.array(ds_storm_ids) == id_string)[0].shape[0]}\")\n",
    "    df_new = calc_dewpoint(df_new)\n",
    "    if 0 in df_new.shape:\n",
    "        print(f\"Nothing to save for {date}\")\n",
    "    else:\n",
    "        df_new.to_parquet(os.path.join(path_save, \"final\", f\"{date}.parquet\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d81786-238e-475c-82f3-78093364f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dewpoint_levels = [f't_dewpoint_{h}' for h in heights]\n",
    "\n",
    "RH0_count = 0\n",
    "if df_new.isna().sum().sum() > 0:\n",
    "    idx, idx_col = np.where(df_new[dewpoint_levels].isnull())\n",
    "    RH0_count += len(idx)\n",
    "    for ix, ixc in zip(idx, idx_col):\n",
    "        height = heights[ixc]\n",
    "        if df_new.at[ix, f'relative_humidity_unitless_{height}'] == 0.0:\n",
    "            df_new.at[ix, f'relative_humidity_unitless_{height}'] == 1.0\n",
    "            RH = units.Quantity(1.0/100., \"dimensionless\")\n",
    "        elif df_new.at[ix, f'relative_humidity_unitless_{height}'] < 0.0:\n",
    "            df_new.at[ix, f'relative_humidity_unitless_{height}'] == 1.0\n",
    "            RH = units.Quantity(1.0/100., \"dimensionless\")\n",
    "        else:\n",
    "            print(f\"RH not 0.0% at {ix, ixc}\")\n",
    "            break\n",
    "        TMP = units.Quantity(df_new.at[ix, f'temperature_kelvins_{height}'] + 273.15, \"K\")\n",
    "        df_new.at[ix, dewpoint_levels[ixc]] = np.array(dewpoint_from_relative_humidity(TMP, RH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dd437-8a62-4308-844e-255a69c19e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.at[ix, f'relative_humidity_unitless_{height}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0960cc7-2f6f-492d-8657-6e5b184d5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.at[ix, f't_dewpoint_{height}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd66f5-91cc-4930-8436-2170341f5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.at[ix, f'temperature_kelvins_{height}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830a805-3584-4bcf-991b-e06aef55ad3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
